{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fc network\n",
    "layers = []\n",
    "layers.append(nn.Linear(784, 512))\n",
    "layers.append(nn.ReLU())\n",
    "layers.append(nn.Linear(512, 256))\n",
    "layers.append(nn.ReLU())\n",
    "layers.append(nn.Linear(256, 128))\n",
    "layers.append(nn.ReLU())\n",
    "layers.append(nn.Linear(128, 10))\n",
    "layers.append(nn.LogSoftmax(dim=1))\n",
    "fc_net = nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "conv_net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xavier_init(model):\n",
    "    for m in model:\n",
    "        if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "            nn.init.xavier_normal(m.weight)\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            nn.init.constant(m.weight, 1)\n",
    "            nn.init.constant(m.bias, 0)\n",
    "            \n",
    "def kaiming_init(model):\n",
    "    for m in model:\n",
    "        if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "            nn.init.kaiming_normal(m.weight)\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            nn.init.constant(m.weight, 1)\n",
    "            nn.init.constant(m.bias, 0)\n",
    "\n",
    "def orthogonal_init(model):\n",
    "    for m in model:\n",
    "        if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "            nn.init.orthogonal(m.weight)\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            nn.init.constant(m.weight, 1)\n",
    "            nn.init.constant(m.bias, 0)\n",
    "\n",
    "def selu_init(model):\n",
    "    for m in model:\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "            nn.init.normal(m.weight, 0, sqrt(1. / n))\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            n = m.out_features\n",
    "            nn.init.normal(m.weight, 0, sqrt(1. / n))\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            nn.init.constant(m.weight, 1)\n",
    "            nn.init.constant(m.bias, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_reg(model):\n",
    "    l2_loss = Variable(torch.FloatTensor(1), requires_grad=True)\n",
    "    for W in model.parameters():\n",
    "        l2_loss = l2_loss + (0.5 * W.norm(2) ** 2)\n",
    "    return l2_loss\n",
    "\n",
    "def l1_reg(model):\n",
    "    l1_loss = Variable(torch.FloatTensor(1), requires_grad=True)\n",
    "    for W in model.parameters():\n",
    "        l1_loss = l1_loss + W.norm(1)\n",
    "    return l1_loss\n",
    "\n",
    "def orthogonal_reg(model):\n",
    "    orth_loss = Variable(torch.FloatTensor(1), requires_grad=True)\n",
    "    for W in model.parameters():\n",
    "        W_reshaped = W.view(W.shape[0], -1)\n",
    "        sym = torch.mm(W_reshaped, torch.t(W_reshaped))\n",
    "        sym -= Variable(torch.eye(W_reshaped.shape[0]))\n",
    "        orth_loss = orth_loss + sym.sum()\n",
    "    return orth_loss\n",
    "\n",
    "def max_norm(model, max_val=3, eps=1e-8):\n",
    "    \"\"\"\n",
    "    Rescale weight vector by (c/L) if L2 norm \n",
    "    greater than `max_val`.\n",
    "    \"\"\"\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'bias' not in name:\n",
    "            norm = param.norm(2, dim=0, keepdim=True) ** 2\n",
    "            desired = torch.clamp(norm, 0, max_val)\n",
    "            param = param * (desired / (eps + norm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orth_loss = Variable(torch.FloatTensor(1), requires_grad=True)\n",
    "for name, param in model.named_parameters():\n",
    "    if 'bias' not in name:\n",
    "        W_reshaped = W.view(W.shape[0], -1)\n",
    "        sym = torch.mm(W_reshaped, torch.t(W_reshaped))\n",
    "        sym -= Variable(torch.eye(W_reshaped.shape[0]))\n",
    "        orth_loss = orth_loss + sym.sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
